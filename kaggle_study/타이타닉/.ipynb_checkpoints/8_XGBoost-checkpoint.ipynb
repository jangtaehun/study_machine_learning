{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58af900b-d62f-4a72-8af0-82afc6b878b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import plot_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54697e21-5d01-4f4c-bc72-8f091051f31a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "titanic_df = pd.read_csv('./titanic/titanic_train.csv')\n",
    "y = titanic_df[\"Survived\"]\n",
    "feature_name = titanic_df.columns\n",
    "titanic_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a76e75a7-4ad5-4c1f-ab38-a3adbca74cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Survived  Pclass     Sex   Age  SibSp  Parch     Fare Cabin Embarked\n",
      "0         0       3    male  22.0      1      0   7.2500     N        S\n",
      "1         1       1  female  38.0      1      0  71.2833   C85        C\n",
      "2         1       3  female  26.0      0      0   7.9250     N        S \n",
      "\n",
      "\n",
      "   Pclass  Sex       Age  SibSp  Parch      Fare  Cabin  Embarked\n",
      "0       3    1 -0.592481      1      0 -0.502445    146         3\n",
      "1       1    0  0.638789      1      0  0.786845     81         0\n",
      "2       3    0 -0.284663      0      0 -0.488854    146         3\n"
     ]
    }
   ],
   "source": [
    "def fillna(df):\n",
    "    df['Cabin'] = df['Cabin'].fillna('N')\n",
    "    df['Embarked'] = df['Embarked'].fillna('N')\n",
    "    imputer = SimpleImputer(missing_values=np.nan, strategy='mean') #missing_values=np.nan 모든 결측값을 대체한다. / strategy='mean' 평균으로 대체한다.\n",
    "    age_array = df['Age'].to_numpy().reshape(-1, 1)\n",
    "    imputer.fit(age_array)\n",
    "    df['Age'] = imputer.transform(age_array)\n",
    "    return df\n",
    "\n",
    "\n",
    "def drop_features(df):\n",
    "    df.drop(['PassengerId','Name','Ticket'], axis=1, inplace=True)\n",
    "    print(df.head(3), \"\\n\\n\")\n",
    "\n",
    "    df = df.drop('Survived', axis=1, inplace=False)\n",
    "    return df\n",
    "\n",
    "\n",
    "# 레이블\n",
    "def encode_features_label(df):\n",
    "    features = ['Cabin', 'Sex', 'Embarked']\n",
    "    le = LabelEncoder()\n",
    "    for feature in features:\n",
    "        le.fit(df[feature])\n",
    "        df[feature] = le.transform(df[feature])\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# 표준화 => 2차원 데이터\n",
    "def stscaler(df):\n",
    "    features = ['Age', 'Fare']\n",
    "    sc = StandardScaler()\n",
    "    for feature in features:\n",
    "        df[[feature]] = sc.fit_transform(df[[feature]])\n",
    "    return df\n",
    "    \n",
    "\n",
    "# # 원핫\n",
    "# # one-hot 인코딩을 하면 많은 0 값을 포함하기 때문에, 이러한 데이터를 희소 행렬 형식으로 저장하면 메모리 사용량을 크게 줄일 수 있다.\n",
    "# # ColumnTransformer는 인코딩된 데이터를 OneHotEncoder를 통해 처리한 후에 희소 행렬 형태로 반환\n",
    "# def encode_features_onehot(df):\n",
    "#     ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1, 6, 7])], remainder='passthrough')\n",
    "#     df = ct.fit_transform(df)\n",
    "#     # df = pd.DataFrame(df.toarray()) # 희소 행렬을 Dense 형태로 변환 후 DataFrame으로 변환\n",
    "#     return df\n",
    "\n",
    "\n",
    "titanic_df = fillna(titanic_df)\n",
    "titanic_df = drop_features(titanic_df)\n",
    "\n",
    "titanic_df = stscaler(titanic_df)\n",
    "\n",
    "# titanic_df = encode_features_onehot(titanic_df)\n",
    "titanic_df = encode_features_label(titanic_df)\n",
    "print(titanic_df[:3])\n",
    "\n",
    "\n",
    "# 전체 데이터 중 80%는 학습용 데이터, 20%는 테스트용 데이터 추출\n",
    "X_train, X_test, y_train, y_test = train_test_split(titanic_df, y, test_size=0.2, random_state=156 )\n",
    "\n",
    "# 위에서 만든 X_train, y_train을 다시 쪼개서 90%는 학습과 10%는 검증용 데이터로 분리 \n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=156 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c48b6d74-980d-4d69-bd0a-2c340e83e407",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.64510\teval-logloss:0.62141\n",
      "[1]\ttrain-logloss:0.62614\teval-logloss:0.60225\n",
      "[2]\ttrain-logloss:0.60828\teval-logloss:0.58399\n",
      "[3]\ttrain-logloss:0.59165\teval-logloss:0.56717\n",
      "[4]\ttrain-logloss:0.57653\teval-logloss:0.55177\n",
      "[5]\ttrain-logloss:0.56274\teval-logloss:0.53772\n",
      "[6]\ttrain-logloss:0.55092\teval-logloss:0.52502\n",
      "[7]\ttrain-logloss:0.53963\teval-logloss:0.51317\n",
      "[8]\ttrain-logloss:0.52893\teval-logloss:0.50203\n",
      "[9]\ttrain-logloss:0.51890\teval-logloss:0.49222\n",
      "[10]\ttrain-logloss:0.50966\teval-logloss:0.48304\n",
      "[11]\ttrain-logloss:0.50111\teval-logloss:0.47414\n",
      "[12]\ttrain-logloss:0.49391\teval-logloss:0.46585\n",
      "[13]\ttrain-logloss:0.48695\teval-logloss:0.45824\n",
      "[14]\ttrain-logloss:0.48008\teval-logloss:0.45088\n",
      "[15]\ttrain-logloss:0.47442\teval-logloss:0.44502\n",
      "[16]\ttrain-logloss:0.46843\teval-logloss:0.43906\n",
      "[17]\ttrain-logloss:0.46352\teval-logloss:0.43376\n",
      "[18]\ttrain-logloss:0.45869\teval-logloss:0.42792\n",
      "[19]\ttrain-logloss:0.45439\teval-logloss:0.42366\n",
      "[20]\ttrain-logloss:0.45038\teval-logloss:0.41924\n",
      "[21]\ttrain-logloss:0.44661\teval-logloss:0.41516\n",
      "[22]\ttrain-logloss:0.44310\teval-logloss:0.41123\n",
      "[23]\ttrain-logloss:0.43958\teval-logloss:0.40705\n",
      "[24]\ttrain-logloss:0.43648\teval-logloss:0.40444\n",
      "[25]\ttrain-logloss:0.43358\teval-logloss:0.40116\n",
      "[26]\ttrain-logloss:0.43020\teval-logloss:0.39764\n",
      "[27]\ttrain-logloss:0.42764\teval-logloss:0.39470\n",
      "[28]\ttrain-logloss:0.42467\teval-logloss:0.39128\n",
      "[29]\ttrain-logloss:0.42238\teval-logloss:0.38923\n",
      "[30]\ttrain-logloss:0.41975\teval-logloss:0.38647\n",
      "[31]\ttrain-logloss:0.41754\teval-logloss:0.38335\n",
      "[32]\ttrain-logloss:0.41558\teval-logloss:0.38111\n",
      "[33]\ttrain-logloss:0.41333\teval-logloss:0.37877\n",
      "[34]\ttrain-logloss:0.41145\teval-logloss:0.37598\n",
      "[35]\ttrain-logloss:0.40976\teval-logloss:0.37398\n",
      "[36]\ttrain-logloss:0.40783\teval-logloss:0.37200\n",
      "[37]\ttrain-logloss:0.40623\teval-logloss:0.36967\n",
      "[38]\ttrain-logloss:0.40472\teval-logloss:0.36744\n",
      "[39]\ttrain-logloss:0.40331\teval-logloss:0.36605\n",
      "[40]\ttrain-logloss:0.40193\teval-logloss:0.36418\n",
      "[41]\ttrain-logloss:0.40065\teval-logloss:0.36272\n",
      "[42]\ttrain-logloss:0.39880\teval-logloss:0.36147\n",
      "[43]\ttrain-logloss:0.39746\teval-logloss:0.35975\n",
      "[44]\ttrain-logloss:0.39592\teval-logloss:0.36036\n",
      "[45]\ttrain-logloss:0.39479\teval-logloss:0.35945\n",
      "[46]\ttrain-logloss:0.39346\teval-logloss:0.36099\n",
      "[47]\ttrain-logloss:0.39240\teval-logloss:0.35977\n",
      "[48]\ttrain-logloss:0.39112\teval-logloss:0.36011\n",
      "[49]\ttrain-logloss:0.38976\teval-logloss:0.36083\n",
      "[50]\ttrain-logloss:0.38865\teval-logloss:0.35914\n",
      "[51]\ttrain-logloss:0.38741\teval-logloss:0.35995\n",
      "[52]\ttrain-logloss:0.38623\teval-logloss:0.36152\n",
      "[53]\ttrain-logloss:0.38509\teval-logloss:0.36241\n",
      "[54]\ttrain-logloss:0.38417\teval-logloss:0.36141\n",
      "[55]\ttrain-logloss:0.38308\teval-logloss:0.36044\n",
      "[56]\ttrain-logloss:0.38191\teval-logloss:0.35989\n",
      "[57]\ttrain-logloss:0.38080\teval-logloss:0.36149\n",
      "[58]\ttrain-logloss:0.37982\teval-logloss:0.36249\n",
      "[59]\ttrain-logloss:0.37875\teval-logloss:0.36203\n",
      "[60]\ttrain-logloss:0.37772\teval-logloss:0.36366\n",
      "[61]\ttrain-logloss:0.37682\teval-logloss:0.36472\n",
      "[62]\ttrain-logloss:0.37608\teval-logloss:0.36390\n",
      "[63]\ttrain-logloss:0.37513\teval-logloss:0.36553\n",
      "[64]\ttrain-logloss:0.37423\teval-logloss:0.36464\n",
      "[65]\ttrain-logloss:0.37322\teval-logloss:0.36413\n",
      "[66]\ttrain-logloss:0.37232\teval-logloss:0.36576\n",
      "[67]\ttrain-logloss:0.37155\teval-logloss:0.36689\n",
      "[68]\ttrain-logloss:0.37042\teval-logloss:0.36684\n",
      "[69]\ttrain-logloss:0.36972\teval-logloss:0.36770\n",
      "[70]\ttrain-logloss:0.36906\teval-logloss:0.36891\n",
      "[71]\ttrain-logloss:0.36823\teval-logloss:0.36872\n",
      "[72]\ttrain-logloss:0.36740\teval-logloss:0.37038\n",
      "[73]\ttrain-logloss:0.36679\teval-logloss:0.37133\n",
      "[74]\ttrain-logloss:0.36595\teval-logloss:0.37102\n",
      "[75]\ttrain-logloss:0.36503\teval-logloss:0.37100\n",
      "[76]\ttrain-logloss:0.36406\teval-logloss:0.37117\n",
      "[77]\ttrain-logloss:0.36302\teval-logloss:0.37064\n",
      "[78]\ttrain-logloss:0.36250\teval-logloss:0.37163\n",
      "[79]\ttrain-logloss:0.36164\teval-logloss:0.37062\n",
      "[80]\ttrain-logloss:0.36074\teval-logloss:0.37074\n",
      "[81]\ttrain-logloss:0.35995\teval-logloss:0.37054\n",
      "[82]\ttrain-logloss:0.35947\teval-logloss:0.37152\n",
      "[83]\ttrain-logloss:0.35867\teval-logloss:0.37058\n",
      "[84]\ttrain-logloss:0.35804\teval-logloss:0.37022\n",
      "[85]\ttrain-logloss:0.35714\teval-logloss:0.36961\n",
      "[86]\ttrain-logloss:0.35623\teval-logloss:0.36890\n",
      "[87]\ttrain-logloss:0.35541\teval-logloss:0.36911\n",
      "[88]\ttrain-logloss:0.35497\teval-logloss:0.37008\n",
      "[89]\ttrain-logloss:0.35426\teval-logloss:0.36994\n",
      "[90]\ttrain-logloss:0.35380\teval-logloss:0.37047\n",
      "[91]\ttrain-logloss:0.35338\teval-logloss:0.37095\n",
      "[92]\ttrain-logloss:0.35272\teval-logloss:0.37085\n",
      "[93]\ttrain-logloss:0.35201\teval-logloss:0.37030\n",
      "[94]\ttrain-logloss:0.35159\teval-logloss:0.37082\n",
      "[95]\ttrain-logloss:0.35120\teval-logloss:0.37130\n",
      "[96]\ttrain-logloss:0.35058\teval-logloss:0.37072\n",
      "[97]\ttrain-logloss:0.34994\teval-logloss:0.37063\n",
      "[98]\ttrain-logloss:0.34929\teval-logloss:0.37014\n",
      "[99]\ttrain-logloss:0.34891\teval-logloss:0.37035\n",
      "[100]\ttrain-logloss:0.34830\teval-logloss:0.37028\n"
     ]
    }
   ],
   "source": [
    "# 만약 구버전 XGBoost에서 DataFrame으로 DMatrix 생성이 안될 경우 X_train.values로 넘파이 변환. \n",
    "# 학습, 검증, 테스트용 DMatrix를 생성. \n",
    "dtr = xgb.DMatrix(data=X_tr, label=y_tr)\n",
    "dval = xgb.DMatrix(data=X_val, label=y_val)\n",
    "dtest = xgb.DMatrix(data=X_test , label=y_test)\n",
    "\n",
    "params = { 'max_depth':3,\n",
    "           'eta': 0.05, # learning-rate\n",
    "           'objective':'binary:logistic', #iteration\n",
    "           'eval_metric':'logloss'\n",
    "        }\n",
    "num_rounds = 400 # n_estermators\n",
    "\n",
    "\n",
    "# 학습 데이터 셋은 'train' 또는 평가 데이터 셋은 'eval' 로 명기합니다. \n",
    "eval_list = [(dtr,'train'),(dval,'eval')] # 또는 eval_list = [(dval,'eval')] 만 명기해도 무방. \n",
    "\n",
    "# 하이퍼 파라미터와 early stopping 파라미터를 train( ) 함수의 파라미터로 전달\n",
    "xgb_model = xgb.train(params = params , dtrain=dtr , num_boost_round=num_rounds , \\\n",
    "                      early_stopping_rounds=50, evals=eval_list )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "016eb9b9-12ea-478a-9b3e-1ed7b6815793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict( ) 수행 결과값을 10개만 표시, 예측 확률 값으로 표시됨\n",
      "[0.561 0.141 0.147 0.163 0.956 0.139 0.63  0.504 0.132 0.381] \n",
      "\n",
      "예측값 10개만 표시: [1, 0, 0, 0, 1, 0, 1, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# predict()를 통해 예측 확률값을 반환하고 예측 값으로 변환\n",
    "pred_probs = xgb_model.predict(dtest)\n",
    "print('predict( ) 수행 결과값을 10개만 표시, 예측 확률 값으로 표시됨')\n",
    "print(np.round(pred_probs[:10],3), \"\\n\")\n",
    "\n",
    "# 예측 확률이 0.5 보다 크면 1 , 그렇지 않으면 0 으로 예측값 결정하여 List 객체인 preds에 저장 \n",
    "preds = [ 1 if x > 0.5 else 0 for x in pred_probs ]\n",
    "print('예측값 10개만 표시:',preds[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46650f61-a91c-4e33-96e4-96d756217cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[96 11]\n",
      " [22 50]]\n",
      "정확도: 0.8156, 정밀도: 0.8197, 재현율: 0.6944,    F1: 0.7519, AUC:0.8786\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Booster' object has no attribute 'accuracy_score'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m get_clf_eval(y_test , preds, pred_probs)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGBM - train: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccuracy_score\u001b[49m(X_train,\u001b[38;5;250m \u001b[39my_train)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGBM - test: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mxgb_model\u001b[38;5;241m.\u001b[39maccuracy_score(X_test,\u001b[38;5;250m \u001b[39my_test)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     26\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m12\u001b[39m))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Booster' object has no attribute 'accuracy_score'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "%matplotlib inline\n",
    "\n",
    "def get_clf_eval(y_test, pred=None, pred_proba=None):\n",
    "    confusion = confusion_matrix( y_test, pred)\n",
    "    accuracy = accuracy_score(y_test , pred)\n",
    "    precision = precision_score(y_test , pred)\n",
    "    recall = recall_score(y_test , pred)\n",
    "    f1 = f1_score(y_test,pred)\n",
    "    # ROC-AUC 추가 \n",
    "    roc_auc = roc_auc_score(y_test, pred_proba)\n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    # ROC-AUC print 추가\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f},\\\n",
    "    F1: {3:.4f}, AUC:{4:.4f}'.format(accuracy, precision, recall, f1, roc_auc))\n",
    "\n",
    "get_clf_eval(y_test , preds, pred_probs)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(f\"XGBoost - train: {xgb_model.score(X_train, y_train)}\")\n",
    "print(f\"XGBoost - test: {xgb_model.score(X_test, y_test)}\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 12))\n",
    "plot_importance(xgb_model, ax=ax) # ax가 그림을 그린다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
