{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c7deb4d-e07e-41d5-acfc-533c5ef7d316",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b653744-760d-4a88-adcc-15e78c4c443a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255, \n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "# ImageDataGenerator: 이미지 증강 및 전처리를 위한 도구\n",
    "# rescale=1./255: 모든 픽셀 값을 255로 나눠서 0과 1 사이의 값으로 스케일링, 모델 훈련 시 더 나은 성능을 위해 필수적\n",
    "\n",
    "# shear_range=0.2: 이미지에 랜덤으로 시어 변환을 적용하여 각도 변화를 준다. 이미지의 기울기를 변화시킨다.\n",
    "#                  이미지를 평행 이동하는 것으로, 이미지의 기울기를 변형 = 다양한 시각적 왜곡에 대해 더 견고\n",
    "#                  훈련 데이터의 다양성을 증가시키기 때문에, 모델이 특정 기울기나 시각적 패턴에만 과적합되지 않도록 도와준다.\n",
    "# zoom_range=0.2: 이미지를 랜덤으로 확대 또는 축소\n",
    "#                 모델이 다양한 크기와 확대 수준의 객체에 대해 더 잘 일반화할 수 있도록 돕는다.\n",
    "#                 훈련 데이터에 다양한 크기의 객체를 포함시키므로, 모델이 객체 크기 변화에 대해 보다 견고하게 된다.\n",
    "# -> 모델 일반화 성능을 향상시키기 위해 사용 / 과적합 방지에 유용\n",
    "# -> 다양한 상황에 대해 학습할 수 있도록 돕고, 결과적으로 모델의 성능을 향상\n",
    "\n",
    "# horizontal_flip=True: 이미지를 수평으로 뒤집는다. 데이터 증강을 통해 과적합을 방지하는 데 도움이 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4df2dd29-f3f7-4654-8f6f-7b07a83f6f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory(\n",
    "    '../../data/cnn/training_set',\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "# target_size=(64, 64): 모든 이미지를 64x64 픽셀 크기로 변환. 이는 모델의 입력 크기와 맞추기 위함\n",
    "# batch_size=32: 한 번에 처리할 이미지의 수. 일반적으로 32가 기본값으로 사용\n",
    "#class_mode='binary': 이진 분류 문제이므로 'binary'로 설정. 이는 각 이미지가 두 개의 클래스 중 하나로 분류됨을 의미\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "    '../../data/cnn/test_set',\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f5ac3b6-ec68-41ed-9c3a-6d8f9c7f9cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#building the CNN\n",
    "cnn = keras.models.Sequential()\n",
    "\n",
    "#Convolution\n",
    "cnn.add(keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))\n",
    "#Pooling\n",
    "cnn.add(keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "\n",
    "cnn.add(keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "cnn.add(keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "\n",
    "cnn.add(keras.layers.Flatten())\n",
    "\n",
    "\n",
    "cnn.add(keras.layers.Dense(units=128, activation='relu'))\n",
    "\n",
    "\n",
    "#Output Layer\n",
    "cnn.add(keras.layers.Dense(units=1, activation='sigmoid')) \n",
    "# units=1 -> 최종 출력 계층의 뉴런 숫자, units 파라미터는 각 Dense 층에서 사용할 뉴런(neuron)의 수를 지정 / 이진 분류(0, 1)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08f5d9fd-cd68-42c5-b45a-c7c44cb765fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 55ms/step - accuracy: 0.8091 - loss: 0.4082 - val_accuracy: 0.7925 - val_loss: 0.4639\n",
      "Epoch 2/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 61ms/step - accuracy: 0.8131 - loss: 0.3977 - val_accuracy: 0.7910 - val_loss: 0.4684\n",
      "Epoch 3/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 55ms/step - accuracy: 0.8248 - loss: 0.3785 - val_accuracy: 0.7930 - val_loss: 0.4750\n"
     ]
    }
   ],
   "source": [
    "# cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# cnn.fit(x = training_set, validation_data=test_set, epochs = 25) #validation_data=cnn을 평가하려는 세트\n",
    "\n",
    "\n",
    "cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint('best-cnn-model.keras', save_best_only=True)\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=2, restore_best_weights=True)\n",
    "\n",
    "history = cnn.fit(x = training_set, validation_data=test_set, epochs = 25, callbacks=[checkpoint_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2d002ae-d639-4017-8403-52b5afb68c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "# predict 메소드는 훈련에 사용했던 것과 똑같은 형식에서 불러와야 한다.\n",
    "# 이미지를 불러오고 크기 조정\n",
    "test_image = image.load_img('ddeock/2024_1.png', target_size=(64,64))\n",
    "\n",
    "# pil => 이미지를 배열에 놓는 형식 / pil 이미지 인스턴스를 넘파이 배열로 변환하는 것\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "# 가짜 차원을 추가하거나 batch_size에 상응하는 차원을 추가 / 어디에 추가 차원을 넣을지 -> 항상 첫 번째 차원, 각 배치 안에 다른 이미지들이 들어간다\n",
    "# 배치 차원을 추가하여 배열을 4차원으로 만듭니다. (1, 64, 64, 3) 형식\n",
    "\n",
    "result = cnn.predict(test_image)\n",
    "training_set.class_indices #class_indices: 알맞은 클래스 인덱스를 갖게 된다\n",
    "if result[0][0] == 1:\n",
    "  prediction = 'dog'\n",
    "else:\n",
    "  prediction = 'cat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3579b955-f39f-42b8-9724-2b019403da0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cat'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5c55de-47d5-4a4f-9c5b-54334eaac2c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70072ee-748c-445c-9e43-34a09259b14e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
